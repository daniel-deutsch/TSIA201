{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bitvenveec8fb45d0664948b1777006f3a54cd7",
   "display_name": "Python 3.8.5 64-bit ('venv')"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# TP1: Conversion of Sampling Frequency and STFT\n",
    "\n",
    "*By Daniel Jorge Deutsch, Kevin Kuhl and Brayam Santiago Velandia (25/09/2020)*"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import struct\n",
    "import sys\n",
    "import wave\n",
    "import time\n",
    "from copy import deepcopy\n",
    "from math import ceil\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyaudio\n",
    "from scipy import signal as sig\n",
    "from scipy.io import wavfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Base:\n",
    "\n",
    "    def __init__(self, name, data):\n",
    "        self.name = name \n",
    "        self.data = np.asarray(data)\n",
    "\n",
    "\n",
    "    #------------------------------#\n",
    "    #--- SAMPLES ------------------#\n",
    "    #------------------------------#\n",
    "\n",
    "    def step_split_sample(self, step):\n",
    "        datas = [self.data[i::step] for i in range(step)]\n",
    "        max_len = max([len(data) for data in datas])\n",
    "        for i, data in enumerate(datas):\n",
    "            if len(data) != max_len:\n",
    "                datas[i] = np.append(data, 0)\n",
    "            datas[i] = self.__class__(f\"{self.name}{i}\", datas[i])\n",
    "        return tuple(datas)       \n",
    "\n",
    "\n",
    "    #------------------------------#\n",
    "    #--- PLOTS --------------------#\n",
    "    #------------------------------#\n",
    "    \n",
    "    def time_plot(self, xhighlights=None, yhighlights=None, figsize=(15, 4), save=False):\n",
    "        pass\n",
    "\n",
    "\n",
    "    def spectrogram_plot(self, xhighlights=None, yhighlights=None, figsize=(15, 4), save=False):\n",
    "        pass\n",
    "\n",
    "\n",
    "    # Should use when you have the filter's coefficients\n",
    "    def freqz_plot(self, xhighlights=None, yhighlights=None, figsize=(15, 4), save=False):\n",
    "\n",
    "        freq, mag = sig.freqz(self.data)\n",
    "\n",
    "        # Magnitude\n",
    "        mag = 20*np.log10(np.abs(mag))\n",
    "        mag[np.abs(mag-np.mean(mag)) > 2*np.std(mag)] = np.nan   # Remove outliers for the plot\n",
    "\n",
    "        # Frequency   \n",
    "        freq = freq/(2*np.pi)\n",
    "        \n",
    "        # Plot\n",
    "        plt.figure(figsize=figsize)\n",
    "        plt.plot(freq, mag)\n",
    "        plt.xlim(freq[0], freq[-1])\n",
    "        plt.ylabel(\"Magnitude [(]dB]\")\n",
    "        plt.xlabel(\"Frequency [(rad/sample)/2π]\")\n",
    "        plt.title(f\"Frequency response of {self.name}\")\n",
    "        if xhighlights:\n",
    "            for xhighlight in xhighlights:\n",
    "                plt.axvline(x=xhighlight, color=\"red\")\n",
    "        if yhighlights:\n",
    "            for yhighlight in yhighlights:\n",
    "                plt.hline(y=yhighlight, color=\"red\")\n",
    "        if save:\n",
    "            plt.savefig(f\"./outputs/figures/{self.name}_freqz.png\", dpi=300, bbox_inches=\"tight\")\n",
    "        plt.show() \n",
    "\n",
    "    \n",
    "    # Should use when you have filter's impulse response\n",
    "    def fft_plot(self, xhighlights=None, yhighlights=None, figsize=(15, 4), save=False):      \n",
    "        \n",
    "        # Magnitude\n",
    "        len_fft = 4096                                           # Length of the transformed axis of the output\n",
    "        mag = np.fft.fft(self.data, len_fft)                     # Obtains the magnitude of the signal\n",
    "        mag = np.fft.fftshift(mag)                               # Shifts the zero-frequency component to the center of the spectrum\n",
    "        mag = 20*np.log10(np.abs(mag))                           # Applies log to the result\n",
    "        mag[np.abs(mag-np.mean(mag)) > 2*np.std(mag)] = np.nan   # Remove outliers for the plot\n",
    "\n",
    "        # Frequency\n",
    "        freq = np.linspace(-0.5, 0.5, len(mag))\n",
    "\n",
    "        # Plot\n",
    "        plt.figure(figsize=figsize)\n",
    "        plt.plot(freq, mag)\n",
    "        plt.xlim(freq[0], freq[-1])\n",
    "        plt.ylabel(\"Magnitude [dB]\")\n",
    "        plt.xlabel(\"Frequency [(rad/sample)/2π]\")\n",
    "        plt.title(f\"Frequency response of {self.name}\")\n",
    "        if xhighlights:\n",
    "            for xhighlight in xhighlights:\n",
    "                plt.axvline(x=xhighlight, color=\"red\")\n",
    "        if yhighlights:\n",
    "            for yhighlight in yhighlights:\n",
    "                plt.hline(y=yhighlight, color=\"red\")\n",
    "        if save:\n",
    "            plt.savefig(f\"./outputs/figures/{self.name}_fft.png\", dpi=300, bbox_inches=\"tight\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Signal(Base):\n",
    "\n",
    "    def __init__(self, name, data=None, freq=None, file=None):\n",
    "        if not ((data is None) ^ (file == None)):\n",
    "            raise Exception(\"You must provide a data or a .wav file\")\n",
    "\n",
    "        if freq:\n",
    "            self.freq = int(freq)\n",
    "\n",
    "        if file:\n",
    "            freq, data = wavfile.read(file)\n",
    "            self.freq = int(freq)\n",
    "        Base.__init__(self, name, data)\n",
    "    \n",
    "\n",
    "    #------------------------------#\n",
    "    #--- SHIFTING -----------------#\n",
    "    #------------------------------#\n",
    "\n",
    "    def shift(self, name, power_of_z):\n",
    "        data = self.data\n",
    "        data = np.append(data[power_of_z:], power_of_z*[0]) if power_of_z > 0 else np.append(abs(power_of_z)*[0], data[:power_of_z])\n",
    "        return self.__class__(name, data, self.freq)\n",
    "\n",
    "    \n",
    "    #------------------------------#\n",
    "    #--- SAMPLING -----------------#\n",
    "    #------------------------------#\n",
    "\n",
    "    def under_sample(self, name, M):\n",
    "        datas = self.step_split_sample(M)\n",
    "        return self.__class__(name=name, data=datas[0].data, freq=self.freq/M)\n",
    "\n",
    "\n",
    "    def over_sample(self, name, L):\n",
    "        data = np.insert(self.data, range(1, len(self.data)+1)[::L-1], 0)\n",
    "        return self.__class__(name=name, data=data, freq=self.freq*L) \n",
    "            \n",
    "\n",
    "    #------------------------------#\n",
    "    #--- LISTEN -------------------#\n",
    "    #------------------------------#\n",
    "    def listen(self):\n",
    "        \n",
    "        # Saves the .wav\n",
    "        if not self.freq:\n",
    "            raise Exception(\"the sample freq (sample/sec) must be provided\")\n",
    "        wavfile.write(f\"./outputs/sounds/{self.name}.wav\", self.freq, np.asarray(self.data, dtype=np.int16))\n",
    "\n",
    "        # Uses pyaudio to play the signal\n",
    "        chunk = 1024\n",
    "        pa = pyaudio.PyAudio()\n",
    "        audio = wave.open(f\"./outputs/sounds/{self.name}.wav\", \"rb\")\n",
    "        stream = pa.open(\n",
    "            format = pa.get_format_from_width(audio.getsampwidth()),\n",
    "            channels = audio.getnchannels(),\n",
    "            rate = audio.getframerate(),\n",
    "            output = True\n",
    "        )\n",
    "        data = audio.readframes(chunk)\n",
    "        while data:\n",
    "            stream.write(data)\n",
    "            data = audio.readframes(chunk)\n",
    "        stream.stop_stream()\n",
    "        stream.close()\n",
    "        pa.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Filter(Base):\n",
    "\n",
    "    def apply(self, name, signal):\n",
    "        conv = np.convolve(self.data, signal.data)\n",
    "        return Signal(name, data=conv, freq=signal.freq)"
   ]
  },
  {
   "source": [
    "# 2.1\n",
    "\n",
    "In order to implement the direct resampling, we should use three blocks like shown in the following image:\n",
    "\n",
    "![title](assets/imgs/img01.png)\n",
    "\n",
    "<br>\n",
    "\n",
    "# 2.2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Obtains the input signal x from its file\n",
    "x = Signal(name=\"x\", file=\"./inputs/caravan_48khz.wav\")\n",
    "\n",
    "# Defines the over and under sampling constants\n",
    "L = 2\n",
    "M = 3\n",
    "\n",
    "# Defines the Remez filter params\n",
    "numtaps = 100                       # An even number (can't be too big)\n",
    "trans_width = 1/13                  # ?\n",
    "cutoff = min( 1/(2*L), 1/(2*M) )    # Cutoff frequency (should be 1/(2*M) = 1/6)\n",
    "\n",
    "# Obtains the Remez filter\n",
    "h = Filter(\"h\", sig.remez(numtaps, [0, cutoff, cutoff+trans_width, 1/2], [L, 0]))\n",
    "\n",
    "# Runs the system\n",
    "start_dir = time.perf_counter()      # Start counting (for exercise 2.5)\n",
    "w = x.over_sample(\"w\", L)            # Obtains the over sampled signal w using L=2 (Fw=48*2=96kHz)\n",
    "v = h.apply(\"v\", w)                  # Calculates the convolution v=w*h\n",
    "y = v.under_sample(\"y\", M)           # Undersample v to obtain the output of the system using M=3 (Fy=96/3=32kHz)\n",
    "end_dir = time.perf_counter()        # Ends counting (for exercise 2.5)"
   ]
  },
  {
   "source": [
    "# 2.3\n",
    "\n",
    "We have initially:\n",
    "\n",
    "![title](assets/imgs/img02.png)\n",
    "\n",
    "Which can be written as:\n",
    "\n",
    "![title](assets/imgs/img03.png)\n",
    "\n",
    "Which can also be written as:\n",
    "\n",
    "![title](assets/imgs/img04.png)\n",
    "\n",
    "<br>\n",
    "\n",
    "# 2.4\n",
    "\n",
    "![title](assets/imgs/img05.png)\n",
    "![title](assets/imgs/img06.png)\n",
    "![title](assets/imgs/img07.png)\n",
    "![title](assets/imgs/img08.png)\n",
    "![title](assets/imgs/img09.png)\n",
    "![title](assets/imgs/img10.png)\n",
    "\n",
    "<br>\n",
    "\n",
    "# 2.5"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Obtains the filters\n",
    "H0, H1 = h.step_split_sample(L)\n",
    "H00, H01, H02 = H0.step_split_sample(M)\n",
    "H10, H11, H12 = H1.step_split_sample(M)\n",
    "\n",
    "# Starts counting (for exercise 2.5)\n",
    "start_opt = time.perf_counter()\n",
    "\n",
    "# Obtains all the k's\n",
    "w0 = x.shift(\"w0\", 1)\n",
    "w1 = w0.shift(\"w1\", -1)\n",
    "w2 = w1.shift(\"w2\", -1)\n",
    "w3 = x\n",
    "w4 = w3.shift(\"w4\", -1)\n",
    "w5 = w4.shift(\"w5\", -1)\n",
    "\n",
    "# Obtains all the v's\n",
    "v0 = w0.under_sample(\"v0\", M)\n",
    "v1 = w1.under_sample(\"v1\", M)\n",
    "v2 = w2.under_sample(\"v2\", M)\n",
    "v3 = w3.under_sample(\"v3\", M)\n",
    "v4 = w4.under_sample(\"v4\", M)\n",
    "v5 = w5.under_sample(\"v5\", M)\n",
    "\n",
    "# Obtains all the u's\n",
    "u0 = H00.apply(\"u0\", v0)\n",
    "u1 = H01.apply(\"u0\", v1)\n",
    "u2 = H02.apply(\"u0\", v2)\n",
    "u3 = H10.apply(\"u0\", v3)\n",
    "u4 = H11.apply(\"u0\", v4)\n",
    "u5 = H12.apply(\"u0\", v5)\n",
    "\n",
    "# Obtains all the k's\n",
    "k0 = Signal(\"k0\", u0.data+u1.data+u2.data, u0.freq)\n",
    "k1 = Signal(\"k1\", u3.data+u4.data+u5.data, u3.freq)\n",
    "\n",
    "# Obtains all the p's\n",
    "p0 = k0.over_sample(\"p0\", L)\n",
    "p1 = k1.over_sample(\"p1\", L)\n",
    "\n",
    "# Obtains all the q's\n",
    "q0 = p0.shift(\"q0\", -1)\n",
    "\n",
    "# Obtains y\n",
    "y = Signal(\"y\", q0.data+p1.data, q0.freq)\n",
    "\n",
    "# Ends counting (for exercise 2.5)\n",
    "end_opt = time.perf_counter()\n",
    "\n",
    "# Listen to the output\n",
    "y.listen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Direct implementation execution time: 0.1871553999990283\nOptimal implementation execution time: 0.13018709999960265\n"
    }
   ],
   "source": [
    "print(f\"Direct implementation execution time: {end_dir-start_dir}\")\n",
    "print(f\"Optimal implementation execution time: {end_opt-start_opt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}